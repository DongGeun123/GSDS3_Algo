{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf -r *.xlsx\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b879a080",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2232544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Complete Pokedex V1.1.csv', engine='python', low_memory=True)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf022d5b",
   "metadata": {},
   "source": [
    "* 데이터를 살펴본 결과\n",
    "    - 범주형 변수가 매우 많음\n",
    "    - 서로 겹치는 값들, 즉 variability가 그다지 높지 않은 변수들이 매우 많음\n",
    "    - 따라서 logistic regression, LDA 등의 linear model보다는 Tree 계열의 모델이 적절할 것으로 사료됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543880fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff9765",
   "metadata": {},
   "source": [
    "# First task - Type Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['generation'] < 8]\n",
    "test = df[df['generation'] == 8]\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e42feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05ab13",
   "metadata": {},
   "source": [
    "# EDA + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9da6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generation별 pokemon 마리 수\n",
    "gen_count = train[['generation', 'pokemon_name']].groupby(by=['generation']).count()\n",
    "gen_count.reset_index(drop=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='generation', y='pokemon_name', data=gen_count)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generation별 type의 개수\n",
    "gen_type = train[['generation', 'type_1', 'pokemon_name']].groupby(by=['generation', 'type_1']).count()\n",
    "gen_type.reset_index(drop=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(36, 6))\n",
    "for gen in sorted(gen_type['generation'].unique()):\n",
    "    subdf = gen_type[gen_type['generation'] == gen]\n",
    "    plt.subplot(int(f\"24{gen}\"))\n",
    "    sns.barplot(x='type_1', y='pokemon_name', data=subdf)\n",
    "    plt.title(f\"Generation {gen}\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## type별 pokemon 마리 수\n",
    "type_count = train[['type_1', 'pokemon_name']].groupby(by=['type_1']).count()\n",
    "type_count.reset_index(drop=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(11.5, 4))\n",
    "sns.barplot(x='type_1', y='pokemon_name', data=type_count)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdaf70d",
   "metadata": {},
   "source": [
    "* type별 분포가 상당히 불균형 - 만약에 어떤 새로운 포켓몬이 들어올 경우 물타입으로 분류할 가능성이 높아짐 - sampling 필요할듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "## type별 height and weight에 차이가 있을까?\n",
    "type_compare = train[['type_1', 'height', 'weight']].groupby(by=['type_1']).mean(numeric_only=False)\n",
    "type_compare.reset_index(drop=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(11, 8))\n",
    "plt.subplot(211)\n",
    "sns.barplot(x='type_1', y='height', data=type_compare)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(212)\n",
    "sns.barplot(x='type_1', y='weight', data=type_compare)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## type별 hit point\n",
    "type_compare = train[['type_1', 'hit_points']].groupby(by=['type_1']).mean(numeric_only=False)\n",
    "type_compare.reset_index(drop=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(11.5, 5))\n",
    "sns.barplot(x='type_1', y='hit_points', data=type_compare)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac305f",
   "metadata": {},
   "source": [
    "* Type 관련 결측치 문제\n",
    "    - type2는 포켓몬 도감에 이미 기분류되어 있음 <- 즉 결측치를 제거하는 것이 의미가 없음; 오히려 데이터 왜곡할 수 있는 가능성\n",
    "    - 따라서 type과 ability의 경우 결측치가 있는 column은 아예 삭제하는 편이 나음 - 그냥 type의 개수, ability의 개수로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_transformer(df):\n",
    "    type2_null = df[df['type_2'].isnull()].index\n",
    "    abil2_null = df[df['ability_2'].isnull()].index\n",
    "    abil3_null = df[df['ability_3'].isnull()].index\n",
    "    egg2_null = df[df['egg_group_2'].isnull()].index\n",
    "\n",
    "    num_types = np.zeros(shape=df.shape[0])\n",
    "    num_abilities = np.zeros(shape=df.shape[0])\n",
    "    num_eggs = np.zeros(shape=df.shape[0])\n",
    "    for idx in range(df.shape[0]):\n",
    "        if idx in type2_null:\n",
    "            num_types[idx] = 1\n",
    "        else:\n",
    "            num_types[idx] = 2\n",
    "\n",
    "        if (idx in abil2_null) and (idx in abil3_null):\n",
    "            num_abilities[idx] = 1\n",
    "        elif (idx in abil2_null) or (idx in abil3_null):\n",
    "            num_abilities[idx] = 2\n",
    "        else:\n",
    "            num_abilities[idx] = 3\n",
    "\n",
    "        if idx in egg2_null:\n",
    "            num_eggs[idx] = 1\n",
    "        else:\n",
    "            num_eggs[idx] = 2\n",
    "\n",
    "    df['num_types'] = num_types.astype('int')\n",
    "    df['num_abilities'] = num_abilities.astype('int')\n",
    "    df['num_egg_groups'] = num_eggs.astype('int')\n",
    "\n",
    "    ## 진화형태 결측치 역시 진화 단계를 구분할 수 있는 범주형 정수로 대체\n",
    "    df['evolves_from'].fillna(0, inplace=True)\n",
    "\n",
    "    ## evolution type - 0: basic / 1: intermediate / 2: final\n",
    "    evolution = np.zeros(shape=df.shape[0], dtype='int')\n",
    "    for i in range(df.shape[0]):\n",
    "        item = df.iloc[i]\n",
    "        if item['evolves_from'] == 0 and item['final_evolution'] == False:\n",
    "            evolution[i] = 0\n",
    "        elif item['final_evolution'] == False:\n",
    "            evolution[i] = 1\n",
    "        else:\n",
    "            evolution[i] = 2\n",
    "\n",
    "    df['evolution_type'] = evolution\n",
    "    df.drop(['type_2', 'ability_2', 'ability_3', 'egg_group_2', 'evolves_from', 'final_evolution'], \n",
    "            axis=1, inplace=True)\n",
    "\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ea83a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_transformer(train)\n",
    "missing_transformer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 굳이 다른 stat 정보가 있는 상황에서 total, mean, std는 불필요한 정보\n",
    "train.drop(['total_stats', 'mean', 'standard_deviation'], axis=1, inplace=True)\n",
    "test.drop(['total_stats', 'mean', 'standard_deviation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37043eb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## height, weight, bmi distribution\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(321)\n",
    "sns.histplot(train['height'], kde=True)\n",
    "plt.title('Height')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(322)\n",
    "sns.boxplot(train['height'], orient='h')\n",
    "plt.title('Height')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(323)\n",
    "sns.histplot(train['weight'], kde=True)\n",
    "plt.title('Weight')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(324)\n",
    "sns.boxplot(train['weight'], orient='h')\n",
    "plt.title('Weight')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(325)\n",
    "sns.histplot(train['bmi'], kde=True)\n",
    "plt.title('BMI')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(326)\n",
    "sns.boxplot(train['bmi'], orient='h')\n",
    "plt.title('BMI')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4263c43",
   "metadata": {},
   "source": [
    "~~포켓몬 도감을 찾아보니 Gmax(거다이맥스) 또는 Eternamax(무한다이맥스)는 몸무게가 ???로 찍혀있어 10000으로 퉁친듯...~~\n",
    "* measurement error나 data entry error가 아니므로 굳이 제거할 필요가 있을까...?\n",
    "* 그리고 이렇게 치우친 분포를 가진 이상 더더욱 tree 계열 모델로 가야될 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "## category 변수 처리\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "concat = pd.concat([train, test], axis=0)\n",
    "concat.drop(['pokedex_number', 'pokemon_name'], axis=1, inplace=True)\n",
    "\n",
    "cats = []\n",
    "cons = []\n",
    "for col in concat.columns.values:\n",
    "    if concat[col].dtype in [object, bool]:\n",
    "        cats.append(col)\n",
    "    else:\n",
    "        cons.append(col)\n",
    "\n",
    "print(f\"Categorical features: {cats}\")\n",
    "print(f\"Continuous features: {cons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb730771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in cats:\n",
    "    if concat[col].dtype == object:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(concat[col])\n",
    "        concat[col] = le.transform(concat[col])\n",
    "    else:\n",
    "        concat[col] = concat[col].astype(np.uint8)\n",
    "\n",
    "display(concat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d11ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = concat[concat['generation'] < 8]\n",
    "test = concat[concat['generation'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "del concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5383c",
   "metadata": {},
   "source": [
    "## Height - Weight and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전체\n",
    "imp_corr = train[[\"bmi\", \"height\", \"weight\", \"hit_points\", \"attack\", \"defense\"]].corr()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    data=imp_corr,\n",
    "    annot=True,\n",
    "    linewidths=.5,\n",
    "    cmap = 'RdYlBu_r',\n",
    "    vmin = -1, vmax = 1,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## by generation\n",
    "gens = sorted(train['generation'].unique())\n",
    "\n",
    "plt.figure(figsize=(14, 20))\n",
    "for gen in gens:\n",
    "    subdf = train[train['generation'] == gen]\n",
    "    subcorr = subdf[[\"bmi\", \"height\", \"weight\", \"hit_points\", \"attack\", \"defense\"]].corr()\n",
    "    plt.subplot(int(f\"42{gen}\"))\n",
    "    sns.heatmap(\n",
    "        data=subcorr,\n",
    "        annot=True,\n",
    "        linewidths=.5,\n",
    "        cmap = 'RdYlBu_r',\n",
    "        vmin = -1, vmax = 1,\n",
    "    )\n",
    "    plt.title(f\"Generation {gen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e48fb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## scatterplot - height\n",
    "heights = train[[\"height\", \"generation\", \"hit_points\", \"attack\", \"defense\"]]\n",
    "\n",
    "plt.figure(figsize=(13, 30))\n",
    "i = 1\n",
    "for gen in sorted(heights['generation'].unique()):\n",
    "    subdf = heights[(heights['generation'] == gen)]\n",
    "    for col in subdf.columns.values[2:]:\n",
    "        plt.subplot(8, 3, i)\n",
    "        sns.scatterplot(data=subdf, x='height', y=col)\n",
    "        plt.grid(True)\n",
    "        plt.title(f\"Generation {gen} - height & {col}\")\n",
    "        i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466a0a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## scatterplot - weight\n",
    "weights = train[[\"weight\", \"generation\", \"hit_points\", \"attack\", \"defense\"]]\n",
    "\n",
    "plt.figure(figsize=(13, 30))\n",
    "i = 1\n",
    "for gen in sorted(weights['generation'].unique()):\n",
    "    subdf = weights[(weights['generation'] == gen)]\n",
    "    for col in subdf.columns.values[2:]:\n",
    "        plt.subplot(8, 3, i)\n",
    "        sns.scatterplot(data=subdf, x='weight', y=col)\n",
    "        plt.grid(True)\n",
    "        plt.title(f\"Generation {gen} - weight & {col}\")\n",
    "        i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del imp_corr, heights, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb60c6",
   "metadata": {},
   "source": [
    "~~Gmax는 generation 8에만 존재... <- training을 어떻게 시켜야 하나..~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a244ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generation에 따른 height, weight 평균 및 분포 변화\n",
    "groupby = train[['generation', 'height', 'weight']].groupby(by='generation').mean()\n",
    "groupby.sort_values(by='generation', inplace=True)\n",
    "groupby.reset_index(drop=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.barplot(x='generation', y='height', data=groupby)\n",
    "plt.grid(True)\n",
    "plt.title(\"Mean Height over Generation\")\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.boxplot(x='generation', y='height', data=train)\n",
    "plt.grid(True)\n",
    "plt.title(\"Boxplot of Height over Generation\")\n",
    "\n",
    "plt.subplot(223)\n",
    "sns.barplot(x='generation', y='weight', data=groupby)\n",
    "plt.grid(True)\n",
    "plt.title(\"Mean Weight over Generation\")\n",
    "\n",
    "plt.subplot(224)\n",
    "sns.boxplot(x='generation', y='weight', data=train)\n",
    "plt.grid(True)\n",
    "plt.title(\"Boxplot of Weight over Generation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c89874",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db666374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38951977",
   "metadata": {},
   "outputs": [],
   "source": [
    "## regression 위해서 scaling\n",
    "imp_train = train[[\"generation\", \"height\", \"weight\", \"hit_points\", \"attack\", \"defense\"]]\n",
    "imp_test = test[[\"generation\", \"height\", \"weight\", \"hit_points\", \"attack\", \"defense\"]]\n",
    "\n",
    "# Min-Max scaling\n",
    "imp_train_, imp_test_ = imp_train.drop('generation', axis=1), imp_test.drop('generation', axis=1)\n",
    "\n",
    "minmax_height = MinMaxScaler()\n",
    "minmax_height.fit(imp_train_[['height']])\n",
    "imp_train_['height'] = minmax_height.transform(imp_train_[['height']])\n",
    "imp_test_['height'] = minmax_height.transform(imp_test_[['height']])\n",
    "\n",
    "minmax_weight = MinMaxScaler()\n",
    "minmax_weight.fit(imp_train_[['weight']])\n",
    "imp_train_['weight'] = minmax_weight.transform(imp_train_[['weight']])\n",
    "imp_test_['weight'] = minmax_weight.transform(imp_test_[['weight']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "imp_train__, imp_test__ = imp_train.drop('generation', axis=1), imp_test.drop('generation', axis=1)\n",
    "\n",
    "std_height = StandardScaler()\n",
    "std_height.fit(imp_train__[['height']])\n",
    "imp_train__['height'] = std_height.transform(imp_train__[['height']])\n",
    "imp_test__['height'] = std_height.transform(imp_test__[['height']])\n",
    "\n",
    "std_weight = StandardScaler()\n",
    "std_weight.fit(imp_train__[['weight']])\n",
    "imp_train__['weight'] = std_weight.transform(imp_train__[['weight']])\n",
    "imp_test__['weight'] = std_weight.transform(imp_test__[['weight']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cef20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for problems\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555749c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X, y, constant:bool=True, logit:bool=False): \n",
    "    if constant:\n",
    "        X = sm.add_constant(X)\n",
    "    \n",
    "    if logit:\n",
    "        model = sm.Logit(y.astype(float), X.astype(float))\n",
    "    else:\n",
    "        model = sm.OLS(y.astype(float),X.astype(float))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5032d7",
   "metadata": {},
   "source": [
    "### Minmax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train_[['height', 'weight']]\n",
    "y = imp_train_['hit_points']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train_[['height', 'weight']]\n",
    "y = imp_train_['attack']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb37d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train_[['height', 'weight']]\n",
    "y = imp_train_['defense']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324de6f0",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train__[['height', 'weight']]\n",
    "y = imp_train__['hit_points']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train__[['height', 'weight']]\n",
    "y = imp_train__['attack']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b246f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train__[['height', 'weight']]\n",
    "y = imp_train__['defense']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1b19c",
   "metadata": {},
   "source": [
    "### Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e660634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "imp_train___, imp_test___ = imp_train.drop('generation', axis=1), imp_test.drop('generation', axis=1)\n",
    "\n",
    "imp_train___['height'] = np.log(imp_train___['height']*100)\n",
    "imp_test___['height'] = np.log(imp_test___['height']*100)\n",
    "\n",
    "imp_train___['weight'] = np.log(imp_train___['weight']*1000)\n",
    "imp_test___['weight'] = np.log(imp_test___['weight']*1000)\n",
    "\n",
    "imp_train___.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train___[['height', 'weight']]\n",
    "y = imp_train___['hit_points']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train___[['height', 'weight']]\n",
    "y = imp_train___['attack']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imp_train___[['height', 'weight']]\n",
    "y = imp_train___['defense']\n",
    "fit = regression(X=X, y=y)\n",
    "print(fit.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0108d027",
   "metadata": {},
   "source": [
    "# Over Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7abfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in sorted(train['generation'].unique()):\n",
    "    subdf = imp_train[imp_train['generation'] == gen]\n",
    "    subdf['height'] = np.log(subdf['height']*100)\n",
    "    subdf['weight'] = np.log(subdf['weight']*1000)\n",
    "    print(f\"Generation {gen}\")\n",
    "    for target in subdf.columns.values[3:]:\n",
    "        X = subdf[['height', 'weight']]\n",
    "        y = subdf[target]\n",
    "        fit = regression(X=X, y=y)\n",
    "        pvals = fit.fit().pvalues[['height', 'weight']]\n",
    "        rsquared = fit.fit().rsquared\n",
    "        print(f\"\\t{target}  \\t{pvals.index.values}: {np.around(pvals, decimals=5).values}  \\tr2: {rsquared}\")\n",
    "        print(f\"\\tNumber of significant variables: {(pvals <= 0.05).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8778a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del imp_train, imp_train_, imp_train__, imp_train___, imp_test, imp_test_, imp_test__, imp_test___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911759b7",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24790\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "et = ExtraTreesClassifier(random_state=RANDOM_STATE)\n",
    "gbr = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "xgb = XGBClassifier(random_state=RANDOM_STATE)\n",
    "lgb = LGBMClassifier(random_state=RANDOM_STATE)\n",
    "# cb = CatBoostClassifier(random_state=RANDOM_STATE, cat_features=cats.remove('type_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a9a69",
   "metadata": {},
   "source": [
    "## Task one: Type classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f41526",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train.drop('type_1', axis=1), train['type_1']\n",
    "x_test, y_test = test.drop('type_1', axis=1), test['type_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [dt, rf, et, gbr, xgb, lgb]\n",
    "for i, model in enumerate(models):\n",
    "    accuracy = cross_val_score(model, X=x_train, y=y_train, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "    f1 = cross_val_score(model, X=x_train, y=y_train, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "    if i < 4:\n",
    "        print(f\"{model.__class__.__name__}    \\tAccuracy: {np.mean(accuracy):.4f}\\tf1: {np.mean(f1):.4f}\")\n",
    "    else:\n",
    "        print(f\"{model.__class__.__name__}    \\t\\tAccuracy: {np.mean(accuracy):.4f}\\tf1: {np.mean(f1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model tuning\n",
    "import optuna\n",
    "\n",
    "N_SPLITS = 5\n",
    "N_TRIALS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d464094",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = {\n",
    "    \"et\": ExtraTreesClassifier,\n",
    "    \"gbr\": GradientBoostingClassifier,\n",
    "    \"xgb\": XGBClassifier,\n",
    "    \"lgb\": LGBMClassifier,\n",
    "    \"rf\": RandomForestClassifier\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fdcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_best_scores = []\n",
    "task1_best_params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ET\n",
    "def et_objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 40),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3500),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "#     accs = np.zeros(shape=fold.get_n_splits())\n",
    "    f1s = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = ExtraTreesClassifier(**param, random_state=RANDOM_STATE)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "#         accuracy = accuracy_score(y_true=y_val, y_pred=y_pred)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "#         accs[trial] = accuracy\n",
    "        f1s[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(f1s)\n",
    "\n",
    "et_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "et_study.optimize(et_objective, n_trials=N_TRIALS)\n",
    "\n",
    "et_best = et_study.best_trial\n",
    "et_best_params = et_best.params\n",
    "print(f'\\nscore: {et_best.value:.10f}\\nparams: {et_best_params}')\n",
    "\n",
    "task1_best_scores.append(et_best.value)\n",
    "task1_best_params.append(et_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbr_objective(trial):\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2500),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = GradientBoostingClassifier(**param, verbose=0, random_state=RANDOM_STATE)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "gbr_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "gbr_study.optimize(gbr_objective, n_trials=N_TRIALS)\n",
    "\n",
    "gbr_best = gbr_study.best_trial\n",
    "gbr_best_params = gbr_best.params\n",
    "print(f'\\nscore: {gbr_best.value:.10f}\\nparams: {gbr_best_params}')\n",
    "\n",
    "task1_best_scores.append(gbr_best.value)\n",
    "task1_best_params.append(gbr_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b778533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 10.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3500),\n",
    "        'colsample_bynode': trial.suggest_uniform('colsample_bynode', 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = XGBClassifier(**param, n_jobs=-1, random_state=RANDOM_STATE, verbosity=0)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "xgb_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "xgb_study.optimize(xgb_objective, n_trials=N_TRIALS)\n",
    "\n",
    "xgb_best = xgb_study.best_trial\n",
    "xgb_best_params = xgb_best.params\n",
    "print(f'\\nscore: {xgb_best.value:.10f}\\nparams: {xgb_best_params}')\n",
    "\n",
    "task1_best_scores.append(xgb_best.value)\n",
    "task1_best_params.append(xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    param = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 100, 3500),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3500),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = LGBMClassifier(**param, n_jobs=-1, random_state=RANDOM_STATE, verbose=-1)        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "lgb_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "lgb_study.optimize(lgb_objective, n_trials=N_TRIALS)\n",
    "\n",
    "lgb_best = lgb_study.best_trial\n",
    "lgb_best_params = lgb_best.params\n",
    "print(f'\\nscore: {lgb_best.value:.10f}\\nparams: {lgb_best_params}')\n",
    "\n",
    "task1_best_scores.append(lgb_best.value)\n",
    "task1_best_params.append(lgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353cf71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rf_objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(**param, random_state=RANDOM_STATE)        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "rf_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "rf_study.optimize(rf_objective, n_trials=N_TRIALS)\n",
    "\n",
    "rf_best = rf_study.best_trial\n",
    "rf_best_params = rf_best.params\n",
    "print(f'\\nscore: {rf_best.value:.10f}\\nparams: {rf_best_params}')\n",
    "\n",
    "task1_best_scores.append(rf_best.value)\n",
    "task1_best_params.append(rf_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = np.argmax(task1_best_scores)\n",
    "best_param = task1_best_params[best_index]\n",
    "best_model_key = list(final_models.keys())[best_index]\n",
    "best_model = final_models[best_model_key](**best_param, random_state=RANDOM_STATE)\n",
    "print(f\"Best model: {best_model.__class__.__name__}\")\n",
    "\n",
    "best_model.fit(x_train, y_train)\n",
    "y_pred = best_model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "test_f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\\tTest F1: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a56473",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_best_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe7dc1",
   "metadata": {},
   "source": [
    "## Task two: Mythical classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_train = np.zeros(train.shape[0])\n",
    "for i in range(train.shape[0]):\n",
    "    if train['legendary'].iloc[i] == 0 and train['mythical'].iloc[i] == 0:\n",
    "        lm_train[i] = 0\n",
    "    elif train['legendary'].iloc[i] == 0 and train['mythical'].iloc[i] == 1:\n",
    "        lm_train[i] = 1\n",
    "    elif train['legendary'].iloc[i] == 1 and train['mythical'].iloc[i] == 0:\n",
    "        lm_train[i] = 2\n",
    "    else:\n",
    "        lm_train[i] = 3\n",
    "\n",
    "lm_test = np.zeros(test.shape[0])\n",
    "for i in range(test.shape[0]):\n",
    "    if test['legendary'].iloc[i] == 0 and test['mythical'].iloc[i] == 0:\n",
    "        lm_test[i] = 0\n",
    "    elif test['legendary'].iloc[i] == 0 and test['mythical'].iloc[i] == 1:\n",
    "        lm_test[i] = 1\n",
    "    elif test['legendary'].iloc[i] == 1 and test['mythical'].iloc[i] == 0:\n",
    "        lm_test[i] = 2\n",
    "    else:\n",
    "        lm_test[i] = 3\n",
    "        \n",
    "train['lm'] = lm_train\n",
    "test['lm'] = lm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train.drop(['legendary', 'mythical', 'lm'], axis=1), train['lm']\n",
    "x_test, y_test = test.drop(['legendary', 'mythical', 'lm'], axis=1), test['lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b440acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [dt, rf, et, gbr, xgb, lgb]\n",
    "for i, model in enumerate(models):\n",
    "    accuracy = cross_val_score(model, X=x_train, y=y_train, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "    f1 = cross_val_score(model, X=x_train, y=y_train, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "    if i < 4:\n",
    "        print(f\"{model.__class__.__name__}    \\tAccuracy: {np.mean(accuracy):.4f}\\tf1: {np.mean(f1):.4f}\")\n",
    "    else:\n",
    "        print(f\"{model.__class__.__name__}    \\t\\tAccuracy: {np.mean(accuracy):.4f}\\tf1: {np.mean(f1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_best_scores = []\n",
    "task2_best_params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cfa63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ET\n",
    "def et_objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 40),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3500),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "#     accs = np.zeros(shape=fold.get_n_splits())\n",
    "    f1s = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = ExtraTreesClassifier(**param, random_state=RANDOM_STATE)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "#         accuracy = accuracy_score(y_true=y_val, y_pred=y_pred)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "#         accs[trial] = accuracy\n",
    "        f1s[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(f1s)\n",
    "\n",
    "et_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "et_study.optimize(et_objective, n_trials=N_TRIALS)\n",
    "\n",
    "et_best = et_study.best_trial\n",
    "et_best_params = et_best.params\n",
    "print(f'\\nscore: {et_best.value:.10f}\\nparams: {et_best_params}')\n",
    "\n",
    "task2_best_scores.append(et_best.value)\n",
    "task2_best_params.append(et_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0afc3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbr_objective(trial):\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2500),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = GradientBoostingClassifier(**param, verbose=0, random_state=RANDOM_STATE)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "gbr_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "gbr_study.optimize(gbr_objective, n_trials=N_TRIALS)\n",
    "\n",
    "gbr_best = gbr_study.best_trial\n",
    "gbr_best_params = gbr_best.params\n",
    "print(f'\\nscore: {gbr_best.value:.10f}\\nparams: {gbr_best_params}')\n",
    "\n",
    "task2_best_scores.append(gbr_best.value)\n",
    "task2_best_params.append(gbr_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec630a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 10.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3500),\n",
    "        'colsample_bynode': trial.suggest_uniform('colsample_bynode', 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = XGBClassifier(**param, n_jobs=-1, random_state=RANDOM_STATE, verbosity=0)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "xgb_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "xgb_study.optimize(xgb_objective, n_trials=N_TRIALS)\n",
    "\n",
    "xgb_best = xgb_study.best_trial\n",
    "xgb_best_params = xgb_best.params\n",
    "print(f'\\nscore: {xgb_best.value:.10f}\\nparams: {xgb_best_params}')\n",
    "\n",
    "task2_best_scores.append(xgb_best.value)\n",
    "task2_best_params.append(xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf126b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    param = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 100, 3500),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3500),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1.0)\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = LGBMClassifier(**param, n_jobs=-1, random_state=RANDOM_STATE, verbose=-1)        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "lgb_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "lgb_study.optimize(lgb_objective, n_trials=N_TRIALS)\n",
    "\n",
    "lgb_best = lgb_study.best_trial\n",
    "lgb_best_params = lgb_best.params\n",
    "print(f'\\nscore: {lgb_best.value:.10f}\\nparams: {lgb_best_params}')\n",
    "\n",
    "task2_best_scores.append(lgb_best.value)\n",
    "task2_best_params.append(lgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb4e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rf_objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    fold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = np.zeros(shape=fold.get_n_splits())\n",
    "    trial = 0\n",
    "    for tr_idx, val_idx in fold.split(x_train, y_train):\n",
    "        X_tr, X_val = x_train.iloc[tr_idx], x_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = RandomForestClassifier(**param, random_state=RANDOM_STATE)        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_true=y_val, y_pred=y_pred, average='weighted')\n",
    "\n",
    "        scores[trial] = f1\n",
    "        trial += 1\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "rf_study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "rf_study.optimize(rf_objective, n_trials=N_TRIALS)\n",
    "\n",
    "rf_best = rf_study.best_trial\n",
    "rf_best_params = rf_best.params\n",
    "print(f'\\nscore: {rf_best.value:.10f}\\nparams: {rf_best_params}')\n",
    "\n",
    "task2_best_scores.append(rf_best.value)\n",
    "task2_best_params.append(rf_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93498099",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = np.argmax(task2_best_scores)\n",
    "best_param = task2_best_params[best_index]\n",
    "best_model_key = list(final_models.keys())[best_index]\n",
    "best_model = final_models[best_model_key](**best_param, random_state=RANDOM_STATE)\n",
    "print(f\"Best model: {best_model.__class__.__name__}\")\n",
    "\n",
    "best_model.fit(x_train, y_train)\n",
    "y_pred = best_model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "test_f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"weighted\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\\tTest F1: {test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
